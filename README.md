# 🛡️ Cyberbullying Detection System using AI & NLP

A real-time AI-powered system that detects cyberbullying in textual content using Natural Language Processing (NLP) and machine learning. This tool helps identify harmful language in social media comments, chats, and online forums—offering support for moderation, flagging, and digital safety.

---

## 📌 Description

This project leverages **machine learning** and **deep learning (NLP)** models to classify user-generated content (UGC) as *bullying* or *non-bullying*. The solution can be integrated with messaging platforms, websites, or educational tools to help protect users from online abuse.

Key features include:

- 🧠 **Text Classification** using NLP and BERT/LSTM models
- 📷 (Optional) **Image Text Detection** using OCR (EasyOCR or Tesseract)
- 📊 **Streamlit/PyQt GUI** for user interaction
- 🔁 **Real-time or Batch Analysis** for scalable use
- 🔐 **Content Moderation Support** for safe digital environments

---

## 🧠 Model Capabilities

- Binary classification: `Cyberbullying` vs `Safe`
- Trained on annotated datasets (Twitter, Instagram, Kaggle)
- Handles offensive language, threats, and personal attacks
- Adaptable for multilingual input (extendable with translation APIs)

---

## 🛠️ Tech Stack

| Component         | Description                                      |
|------------------|--------------------------------------------------|
| Python            | Main programming language                        |
| scikit-learn      | ML model development (Logistic Regression, SVM) |
| PyTorch / TensorFlow | Deep learning (BERT, LSTM models)           |
| EasyOCR / Tesseract | For OCR in image-based text                  |
| Streamlit / PyQt5 | User interface (GUI)                             |
| Pandas, Numpy     | Data processing                                  |
| Matplotlib, Seaborn | Visualization of model performance           |

---



