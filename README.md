# ğŸ›¡ï¸ Cyberbullying Detection System using AI & NLP

A real-time AI-powered system that detects cyberbullying in textual content using Natural Language Processing (NLP) and machine learning. This tool helps identify harmful language in social media comments, chats, and online forumsâ€”offering support for moderation, flagging, and digital safety.

---

## ğŸ“Œ Description

This project leverages **machine learning** and **deep learning (NLP)** models to classify user-generated content (UGC) as *bullying* or *non-bullying*. The solution can be integrated with messaging platforms, websites, or educational tools to help protect users from online abuse.

Key features include:

- ğŸ§  **Text Classification** using NLP and BERT/LSTM models
- ğŸ“· (Optional) **Image Text Detection** using OCR (EasyOCR or Tesseract)
- ğŸ“Š **Streamlit/PyQt GUI** for user interaction
- ğŸ” **Real-time or Batch Analysis** for scalable use
- ğŸ” **Content Moderation Support** for safe digital environments

---

## ğŸ§  Model Capabilities

- Binary classification: `Cyberbullying` vs `Safe`
- Trained on annotated datasets (Twitter, Instagram, Kaggle)
- Handles offensive language, threats, and personal attacks
- Adaptable for multilingual input (extendable with translation APIs)

---

## ğŸ› ï¸ Tech Stack

| Component         | Description                                      |
|------------------|--------------------------------------------------|
| Python            | Main programming language                        |
| scikit-learn      | ML model development (Logistic Regression, SVM) |
| PyTorch / TensorFlow | Deep learning (BERT, LSTM models)           |
| EasyOCR / Tesseract | For OCR in image-based text                  |
| Streamlit / PyQt5 | User interface (GUI)                             |
| Pandas, Numpy     | Data processing                                  |
| Matplotlib, Seaborn | Visualization of model performance           |

---



